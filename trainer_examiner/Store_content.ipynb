{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38c67b3-7822-499a-87b5-5be7af4034b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d18ba3-eaef-4fd3-9563-7ae148f8a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents= []\n",
    "loader = Docx2txtLoader(\"/home/TeamNLP/Trainer_Examiner/AITrainer/Client/Prudential/faq/data/british_gas/HighMark_FAQ.docx\")\n",
    "# loader2 = Docx2txtLoader(\"demo_api/data/IRA_FAQ.docx\")\n",
    "excel_loader = UnstructuredExcelLoader(\"/home/TeamNLP/Trainer_Examiner/AITrainer/Client/Prudential/faq/data/british_gas/FAQ.xlsx\")\n",
    "documents.extend(loader.load())\n",
    "documents.extend(excel_loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed790cbb-cd68-4473-9a39-839dd2ea4e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/home/TeamNLP/Trainer_Examiner/AITrainer/Client/Prudential/faq/data/british_gas/HighMark_FAQ.docx'}, page_content='Understanding Common Insurance Terms\\n\\nHealth insurance and health insurance terminology can be tricky and sometimes confusing. That’s why we’ve broken down the most common insurance terms in easy-to-understand language. For more information on the rest of the most common insurance terms, please visit\\xa0the Health Insurance Glossary.\\n\\nWhat is the Affordable Care Act (ACA)?\\n\\nThe\\xa0Affordable Care Act (ACA), also referred to as “Obamacare” is care that aims to expand access to coverage, control health care costs and improve health care delivery for U.S. citizens and legal residents. Most U.S. citizens and legal residents are now required to have health insurance coverage or pay a penalty to the government. ACA legislation includes the expansion of\\xa0Medicaid\\xa0eligibility, the establishment of health insurance exchanges and protects health insurance members from denied coverage due to pre-existing conditions.\\n\\nWhat is a claim?\\n\\nA\\xa0claim\\xa0is a request for payment that lists the treatment performed. It’s sent to your insurance company after you receive get covered services.\\n\\nWhat is coinsurance?\\n\\nCoinsurance\\xa0is the percentage you owe for certain some covered services after reaching your deductible. For example, when you pay 20%, your plan pays 80%.\\n\\nWhat is a copay?\\n\\nA\\xa0copay\\xa0is a fixed dollar amount that you pay upfront each time you pay for covered services. Copays can vary based on the service, such as when: seeing your primary care provider, visiting a specialist, or filling a prescription might all have different copays.\\n\\nWhat is a deductible?\\n\\nA\\xa0deductible\\xa0is the set amount you pay for covered services or drug costs before your plan starts paying.\\n\\nWhat is the drug formulary?\\n\\nA\\xa0drug formulary\\xa0is a list of drugs your insurance plan covers. A drug’s formulary may also impact how much you pay for each drug.\\n\\nWhat is an Explanation of Benefits (EOB)?\\n\\nThe\\xa0Explanation of Benefits (EOB)\\xa0is a document that explains the costs for services you received. This includes what the provider billed for, what Highmark paid, and what you will need to pay. The EOB is not a bill, it’s a summary of the charges and payments related to your medical care. It’s designed meant to help you understand how your plan covers the services you received. Members get an EOB after we process certain types of\\xa0claims. The EOB might include:\\n\\nPatient information\\n\\nMember ID number\\n\\nClaims information\\n\\nInformation about your coinsurance, copay and your deductible\\n\\nMember ID number\\n\\nPatient information\\n\\nWhat you owe the provider\\n\\nWhat is out of pocket?\\n\\nThe\\xa0out-of-pocket\\xa0is costs are not covered by your plan. These include\\xa0co-payments, coinsurance, deductibles and fees paid for treatment or prescriptions.\\n\\nWhat is total/maximum/limit out-of-pocket?\\n\\nThe\\xa0total maximum out-of-pocket\\xa0is the most you’d you pay for any covered services within a plan year. Your deductible, coinsurance, and copays all go toward meeting it. If you hit this amount, your plan pays 100% of covered services.'),\n",
       " Document(metadata={'source': '/home/TeamNLP/Trainer_Examiner/AITrainer/Client/Prudential/faq/data/british_gas/FAQ.xlsx'}, page_content='Q1: How does FCA define a vulnerable customer?\\n\\nA1: The FCA defines vulnerability as someone who, due to personal circumstances, is especially susceptible to detriment, particularly when a firm does not act with appropriate levels of care. In this context vulnerable customer is: A customer or household member whose circumstance means there is a risk to health, life or property.\\n\\nQ2: What qualifies a customer or household as vulnerable in this context?\\n\\nA2: A customer or household is considered vulnerable if there is a risk to health, life, or property due to their circumstances.\\n\\nQ3: What is the first step in identifying customer vulnerability?\\n\\nA3: The first step is recognizing indicators that a customer or household member is in a situation that may impact their health, life, or property.\\n\\nQ4: What should be considered if a customer has a medical condition that may affect future contact?\\n\\nA4: You should consider suggesting the addition of a nominee to the account—this could be anyone living in the household or on the contract.\\n\\nQ5: What are some indicators of vulnerability in relation to heating and appliances?\\n\\nA5: Indicators include reliance on heating or certain appliances (e.g., fridge freezer for medication) due to medical conditions or risk to health/life without them.\\n\\nQ6: What types of health conditions might indicate household vulnerability?\\n\\nA6: These include but are not limited to arthritis, poor mobility, asthma, cancer, COPD, cystic fibrosis, diabetes, heart conditions, and use of breathing equipment like oxygen or a sleep apnoea mask.\\n\\nQ7: What are some conversation tips when speaking with customers about gas-related issues?\\n\\nA7: Few conversations are: \"Do you have heating/hot water at the property?\", \"Is there anyone at the property whose health/life is at risk as a result of no heating/hot water?\", \"Is anyone’s medical condition being affected by the current issue?\"\\n\\nQ8: What questions can help identify electrical-related vulnerability?\\n\\nA8: \"Would anyone at the property be at risk without electrics?\", \"Does anyone use medical equipment that requires electricity?\"\\n\\nQ9: What are some important questions regarding kitchen appliances and vulnerability?\\n\\nA9: \"Would anyone be at risk without the use of the appliance?\",\"Is any medication stored in the appliance?\"\\n\\nQ10: What safety advice should be provided to customers without heating?\\n\\nA10: Wear several thin layers of clothing, Wear a hat indoors to reduce heat loss., Stay active, but not to the point of sweating, Drink warm drinks and eat high-energy foods, Use a temporary heater in one room, Avoid alcohol\\n\\nQ11: What should be done once vulnerability is identified?\\n\\nA11: Confirm and record the customer’s best contact number. Where appropriate, escalate the situation by booking an emergency appointment. Provide safety guidance if there’s no heating\\n\\nQ12: How should households with young children be assessed for vulnerability?\\n\\nA12: Age alone does not determine vulnerability, but babies under 12 months are often considered vulnerable as they cannot regulate body temperature. Other factors include medical conditions, weather, and alternative heating availability.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5969cb5c-ba8c-4aee-9692-8cefdec8390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import AzureChatOpenAI,AzureOpenAIEmbeddings\n",
    "from config import configuration\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = configuration['open_ai_cred']['OPENAI_API_TYPE']\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = configuration['open_ai_cred']['OPENAI_API_BASE']\n",
    "os.environ[\"OPENAI_API_KEY\"] = configuration['open_ai_cred']['OPENAI_API_KEY']\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=configuration['open_ai_config']['deployment_name'],  # or your deployment\n",
    "    api_version=configuration['open_ai_config']['openai_api_version'],  # or your api version\n",
    "    temperature=0,\n",
    "    logprobs=False \n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "\tazure_deployment=\"text-embedding-3-small\",\n",
    "    model=\"text-embedding-3-small\",\n",
    "\tapi_key=\"76d132a244d24e658c34e95641e017ae\",\n",
    "\tazure_endpoint = \"https://azureai7383474271.cognitiveservices.azure.com\",\n",
    "\tapi_version='2023-05-15',\n",
    "\tdimensions=1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae9a9b-96cc-4dff-8665-fbbc9ba90ed1",
   "metadata": {},
   "source": [
    "## Chunking Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74db687-a028-4743-ba1f-d4a309d8f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages_to_lines(pages):\n",
    "    document_lines = []\n",
    "    for i, page in enumerate(pages):\n",
    "        metadata = page.metadata\n",
    "        #print(metadata)\n",
    "        lines = page.page_content.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            document_lines.append({\n",
    "                \"content\": line,\n",
    "                \"element_type\": \"NarrativeText\",\n",
    "                \"metadata\":metadata,\n",
    "                \"page_number\": i+1, # page numbers are 1-indexed\n",
    "                \"is_visual\": False,\n",
    "            })\n",
    "    return document_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4148c-69b7-4d9b-ad69-e84c48e5d2cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s=pages_to_lines(documents)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59ba8f-d8ef-41e7-9e16-6b77b5bfab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_lines_str = [line[\"content\"] for line in s]\n",
    "document_str = \"\\n\".join(document_lines_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2743d80-ab3c-4b4c-8597-4c3446f3059f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "document_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e32fb5-392f-4b30-ad79-5f2f4bf0f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections_text(sections, document_lines):\n",
    "    \"\"\"\n",
    "    Takes in a list of DocumentSection objects and returns a list of dictionaries containing the attributes of each Section object plus the content of the section.\n",
    "    \"\"\"\n",
    "    from typing import TypedDict\n",
    "    class Section(TypedDict):\n",
    "        title: str \n",
    "        metadata: list\n",
    "        start: int\n",
    "        end: int\n",
    "        content: str\n",
    "    section_dicts = []\n",
    "    for i,s in enumerate(sections):\n",
    "        if i == len(sections) - 1:\n",
    "            end_index = len(document_lines) - 1\n",
    "        else:\n",
    "            end_index = sections[i+1][\"start_index\"]-1\n",
    "        try:\n",
    "            contents = [document_lines[j][\"content\"] for j in range(s[\"start_index\"], end_index+1)]\n",
    "            metadatas = [document_lines[j][\"metadata\"] for j in range(s[\"start_index\"], end_index+1)]\n",
    "        except Exception as e:\n",
    "            print (\"error in get_sections_text\", e)\n",
    "            print (\"section \", s)\n",
    "            raise e\n",
    "\n",
    "        unique = list({item['source'] for item in metadatas})\n",
    "\n",
    "        section_dicts.append(Section(\n",
    "            title=s[\"title\"],\n",
    "            metadata=unique,\n",
    "            content=\"\\n\".join(contents),\n",
    "            start=s[\"start_index\"],\n",
    "            end=end_index\n",
    "        ))\n",
    "    return section_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7154774-3c27-4874-b0b3-16e0ee4831db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Read the document below and extract a StructuredDocument object from it where each section of the document is centered around a single concept/topic. Whenever possible, your sections (and section titles) should match up with the natural sections of the document (i.e. Introduction, Conclusion, References, etc.). Sections can vary in length, but should generally be anywhere from a few paragraphs to a few pages long.\n",
    "Each line of the document is marked with its line number in square brackets (e.g. [1], [2], [3], etc). Use the line numbers to indicate section start.\n",
    "The start line numbers will be treated as inclusive. For example, if the first line of a section is line 5, the start_index should be 5. Your goal is to find the starting line number of a given section, where a section is a group of lines that are thematically related.\n",
    "The first section must start at the first line number of the document ({start_line} in this case). The sections MUST cover the entire document. \n",
    "Section titles should be descriptive enough such that a person who is just skimming over the section titles and not actually reading the document can get a clear idea of what each section is about.\n",
    "Note: the document provided to you may just be an excerpt from a larger document, rather than a complete document. Therefore, you can't always assume, for example, that the first line of the document is the beginning of the Introduction section and the last line is the end of the Conclusion section (if those section are even present).\n",
    "\"\"\"\n",
    "\n",
    "LANGUAGE_ADDENDUM = \"For your section titles, YOU MUST use the same language as the document. If the document is in English, your section titles should be in English. If the document is in another language, your section titles should be in that language.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf8a18-8cb4-4839-8267-b32185057a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "class DocumentSection(BaseModel):\n",
    "    title: str = Field(description=\"main topic of this section of the document (very descriptive)\")\n",
    "    start_index: int = Field(description=\"line number where the section begins (inclusive)\")\n",
    "    \n",
    "class StructuredDocument(BaseModel):\n",
    "    \"\"\"obtains meaningful sections, each centered around a single concept/topic\"\"\"\n",
    "    sections: List[DocumentSection] = Field(description=\"a list of sections of the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26306a-b637-42bf-9775-b0cbb26f2211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your custom path\n",
    "import os\n",
    "import sys\n",
    "from config import configuration\n",
    "\n",
    "custom_path = '/home/TeamNLP/Trainer_Examiner/AITrainer/Client/British_Gas/DEV/Shweta/faq/'\n",
    "if custom_path not in sys.path:\n",
    "\tsys.path.append(custom_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4825f-c82c-4955-9f43-75ccd07a7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def get_document_with_lines(document_lines, start_line: int, max_characters: int) :\n",
    "    document_with_line_numbers = \"\"\n",
    "    character_count = 0\n",
    "    \n",
    "    for i in range(start_line, len(document_lines)):\n",
    "        line = document_lines[i][\"content\"]\n",
    "        document_with_line_numbers += f\"[{i}] {line}\\n\"\n",
    "        character_count += len(line)\n",
    "        if character_count > max_characters or i == len(document_lines) - 1:\n",
    "            end_line = i\n",
    "            break\n",
    "    return document_with_line_numbers, end_line\n",
    "\n",
    "def get_structured_document(document_with_line_numbers: str, start_line: int, llm_provider: str, model: str, language: str):\n",
    "    \"\"\"\n",
    "    Note: This function relies on Instructor, which only supports certain model providers. That's why this function doesn't use the LLM abstract base class that is used elsewhere in the project.\n",
    "    \"\"\"\n",
    "\n",
    "    formatted_system_prompt = SYSTEM_PROMPT.format(start_line=start_line)\n",
    "    if language != \"en\":\n",
    "        formatted_system_prompt += \"\\n\" + LANGUAGE_ADDENDUM\n",
    "\n",
    "    if llm_provider == \"anthropic\":\n",
    "        base_url = os.environ.get(\"DSRAG_ANTHROPIC_BASE_URL\", None)\n",
    "        if base_url is not None:\n",
    "            client = instructor.from_anthropic(Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"], base_url=base_url))\n",
    "        else:\n",
    "            client = instructor.from_anthropic(Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"]))\n",
    "        return client.chat.completions.create(\n",
    "            model=model,\n",
    "            response_model=StructuredDocument,\n",
    "            max_tokens=4000,\n",
    "            temperature=0.0,\n",
    "            system=formatted_system_prompt,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": document_with_line_numbers,                    \n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "    elif llm_provider == \"openai\":\n",
    "        from langchain_openai import AzureChatOpenAI\n",
    "        os.environ[\"OPENAI_API_TYPE\"] = configuration['open_ai_cred']['OPENAI_API_TYPE']\n",
    "        os.environ[\"AZURE_OPENAI_ENDPOINT\"] = configuration['open_ai_cred']['OPENAI_API_BASE']\n",
    "        os.environ[\"OPENAI_API_KEY\"] = configuration['open_ai_cred']['OPENAI_API_KEY']\n",
    "        llm = AzureChatOpenAI(**{'deployment_name':configuration['open_ai_config']['deployment_name'], 'openai_api_version':configuration['open_ai_config']['openai_api_version']}, temperature=0.1)\n",
    "        # llm=llm.with_structured_output(StructuredDocument)\n",
    "        from langchain_core.prompts import PromptTemplate\n",
    "        from langchain_core.output_parsers import StrOutputParser\n",
    "        parser = JsonOutputParser(pydantic_object=StructuredDocument)\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "        messages = [(\"system\",formatted_system_prompt),(\"human\", document_with_line_numbers),]\n",
    "        # ai_msg = llm.invoke(messages)\n",
    "        strctured_prompt = PromptTemplate(\n",
    "        input_variables=[\"formatted_system_prompt\",\"document_with_line_numbers\",\"source\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        template=\"\"\"\n",
    "\t **System Instructions:**\n",
    "\t {formatted_system_prompt}\n",
    "\t         \n",
    "\t**Format Instructions:**\n",
    "\t{format_instructions}  \n",
    "\t\n",
    "\t**document_with_line_numbers:**\n",
    "\t{document_with_line_numbers}\n",
    "    \n",
    "\t\"\"\"\n",
    "\t)\n",
    "        chain=strctured_prompt | llm | parser\n",
    "\n",
    "        return(chain.invoke({\"formatted_system_prompt\":formatted_system_prompt,\"document_with_line_numbers\":document_with_line_numbers}))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid provider. Must be either 'anthropic' or 'openai'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a5e2c-6b62-4d39-87b2-9df58e4372ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sections(document_lines, max_characters: int = 20000, llm_provider: str = \"openai\", model: str = \"gpt-4o-mini\", language: str = \"en\"):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    - document_lines: list[dict] - the text of the document\n",
    "    - max_iterations: int - the maximum number of iterations to run (used as a safety measure to prevent the possibility of an infinite loop)\n",
    "    - max_characters: int - the maximum number of characters to process in one call to the LLM\n",
    "    - llm_provider: str - the LLM provider to use (either \"anthropic\" or \"openai\")\n",
    "    - model: str - the name of the LLM model to use\n",
    "\n",
    "    Returns\n",
    "    - sections: a list of dictionaries, each containing the following keys:\n",
    "        - title: str - the main topic of this section of the document (very descriptive)\n",
    "        - start: int - line number where the section begins (inclusive)\n",
    "        - end: int - line number where the section ends (inclusive)\n",
    "        - content: str - the text of the section\n",
    "    \"\"\"\n",
    "    max_iterations = 2*(len(document_str) // max_characters + 1)\n",
    "    print(max_iterations)\n",
    "    start_line = 0\n",
    "    all_sections = []\n",
    "    for _ in range(max_iterations):\n",
    "        document_with_line_numbers, end_line = get_document_with_lines(document_lines, start_line, max_characters)\n",
    "        #print(\"docs--->\",document_with_line_numbers)\n",
    "        #print(\"source---->\",len(source))\n",
    "        structured_doc = get_structured_document(document_with_line_numbers,  start_line, llm_provider=llm_provider, model=model, language=language)\n",
    "        #print(\"strucy--------------\",structured_doc)\n",
    "        new_sections = structured_doc[\"sections\"]\n",
    "        #print(\"checkpoint1\")\n",
    "        all_sections.extend(new_sections)\n",
    "        \n",
    "        if end_line >= len(document_lines) - 1:\n",
    "            # reached the end of the document\n",
    "            break\n",
    "        else:\n",
    "            if len(new_sections) > 1:\n",
    "                start_line = all_sections[-1][\"start_index\"] # start from the next line after the last section\n",
    "                all_sections.pop()\n",
    "            else:\n",
    "                start_line = end_line + 1\n",
    "\n",
    "    # get the section text\n",
    "    sections = get_sections_text(all_sections, document_lines)\n",
    "    #print(\"sections---->\",sections)\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eb59f-8d05-4c98-b60b-bc1291d1a1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sections = get_sections(\n",
    "            document_lines=s, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a943b-56b0-4506-aceb-7dc4d8d866c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0506d-4d1f-4dba-879f-e9b941dcf80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\"title: \" + section[\"title\"]+\"\\n\"+section[\"content\"] for section in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc27f0c-91d1-4d47-b66a-fe9a1f9c4e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7c7ce-5998-4538-9507-1b90d134d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067d914-567a-4dd4-a54c-f5d40333dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=[section[\"metadata\"]for section in sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f96d0-f01d-47b4-8262-a6d171923021",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c6712-56f3-4556-9bda-42b854336938",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51651521-4f90-4635-925a-3c59371fb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas=[{'source': metadata[i][0]} for i in range(len(metadata))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b700e3-b328-49ef-a776-28c1d9711e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249ccea-023e-48a9-b4bb-6be428b2d7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64e328e6-cc97-400c-bca0-1c67a7a9c255",
   "metadata": {},
   "source": [
    "## Creating DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a27de1-59bb-405a-a4f2-d10ccc0210b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "class sEmbeddingFunction(EmbeddingFunction):\n",
    "\tdef __call__(self, input: Documents) -> Embeddings:\n",
    "\t\tembeddings_list = [embeddings.embed_query(text) for text in input]\n",
    "\t\treturn embeddings_list\n",
    "\t\t\n",
    "\tdef embed_query(self, text: str) -> List[float]:\n",
    "\t\treturn embeddings.embed_query(text)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9de914-7fdf-417d-9f45-c0d4b6234041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_embeddings=sEmbeddingFunction()\n",
    "persistent_client = chromadb.PersistentClient(path=\"./chroma1\")\n",
    "collection = persistent_client.get_or_create_collection(name=\"britishgas\",embedding_function=custom_embeddings)\n",
    "collection.add(ids=list(map(str, range(len(docs)))), documents=docs, metadatas=[{'source': metadata[i][0]} for i in range(len(metadata))])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"britishgas\",\n",
    "\tembedding_function=custom_embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d4af8-c759-4e2a-8e20-912bc2a26df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_from_client.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cf676-7c5c-4ac7-a01e-8978548e29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store_from_client.similarity_search_with_score(\"What is coinsurance?\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bd8c3c-b0a7-4610-b895-d3beeb684c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_kwargs={\"score_threshold\": 0.3}#{\"k\":k}\n",
    "retriever = vector_store_from_client.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs=search_kwargs)\n",
    "initial_docs=retriever.get_relevant_documents(\"What is the first step in identifying customer vulnerability?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f925c-b563-4797-8ce8-c6d60aef178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94e07b-62d8-4c84-9d87-20e5cd8c273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eaafa0-8686-47c5-a528-f7274a5b52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "pairs = [Document(page_content=doc[0].page_content) for doc in results if doc[1]<=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b7964-fa8f-4901-8c67-d11e6e3ad265",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82940db-b699-4034-97f7-5e114ff37e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(f\"Response: {result.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a038d0-8198-474a-a771-e4d998c89da2",
   "metadata": {},
   "source": [
    "## VectorStore Accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6bdacd-ff43-498e-9a8a-bb8bca131b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"prudential\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./sampledb/prudential\",  # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518e0474-681e-4f34-8af0-462dec659e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"what is head-on collison?\",\n",
    "    k=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345ad617-98a2-4859-80ba-98b7a9a5f949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: title: Introduction to Head-On Collision\n",
      "What is Head On collison?\n",
      "\n",
      "A head-on collision occurs when two vehicles travelling in opposite directions (more or less) collide frontally with each other.\n",
      "\n",
      "Response: title: Causes of Head-On Collision\n",
      "How does Head-On Collision occur?\n",
      "\n",
      "Head-on collisions are among the most devastating types of traffic accidents and are often the result of driver error or negligence. Understanding the key contributing factors can help promote awareness and prevention.\n",
      "\n",
      "1. Distracted Driving\n",
      "Engaging in activities like texting, using a GPS, or adjusting the radio diverts a driver’s attention from the road. These distractions can lead to lane drifting and significantly increase the risk of a head-on collision.\n",
      "\n",
      "2. Impaired Driving\n",
      "Operating a vehicle under the influence of alcohol or drugs impairs judgment, coordination, and reaction time. This makes it more likely for a driver to veer into oncoming traffic.\n",
      "\n",
      "3. Fatigue\n",
      "Drowsy driving can lead to lapses in attention and slower response times. Fatigued drivers may unintentionally drift out of their lanes, increasing the risk of a crash.\n",
      "\n",
      "4. Speeding and Reckless Driving\n",
      "Driving at excessive speeds reduces a driver's ability to respond to sudden obstacles or changes in road conditions. Reckless behaviors such as aggressive overtaking can also lead to dangerous head-on encounters.\n",
      "\n",
      "5. Poor Weather Conditions\n",
      "Adverse weather such as rain, fog, or snow can impair visibility and road traction, making it difficult for drivers to maintain control and stay in their lanes.\n",
      "\n",
      "6. Wrong-Way Driving\n",
      "Entering a one-way street or highway in the wrong direction is a critical error that frequently results in high-speed head-on collisions, especially on limited-access roads\n",
      "\n",
      "Response: title: Introduction to Rear-End Collision\n",
      "What is Rear-end-collison?\n",
      "\n",
      "A rear-end collision is a type of traffic accident where one vehicle crashes into the back of another. A rear-end collision occurs when one vehicle crashes into the back of another. This type of accident is among the most common in the United States, accounting for approximately 29% of all automobile accidents .\n",
      "\n",
      "Response: title: Introduction to Side Collision\n",
      "What is side collision? / How side collision occurs?\n",
      "\n",
      "A side collision, commonly referred to as a T-bone or broadside accident, occurs when the side of one vehicle is struck by the front or rear of another vehicle. These collisions are particularly hazardous due to the limited protection on the sides of vehicles compared to the front or rear.\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"Response: {result.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00d9eb9-ac37-462e-ac8a-a2ac46ef232c",
   "metadata": {},
   "source": [
    "## Using the VectorDB with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b467bf2-2d24-40a6-bd24-2e32d80019b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"OPENAI_API_TYPE\": \"azure\",\n",
    "#     \"AZURE_OPENAI_ENDPOINT\": \"https://cxaicoe-openai.openai.azure.com/\",\n",
    "#     \"OPENAI_API_KEY\": \"f0dd5fb480d74684832ff376296b730b\",\n",
    "#     \"azure_deployment\": \"cx-aicoe-gpt4\",\n",
    "#     \"api_version\": \"2024-09-01-preview\",\n",
    "#     \"model_version\": \"2024-08-06\",\n",
    "#     \"temperature\": 0.0,\n",
    "#     \"max_tokens\": 1024,\n",
    "#     \"logprobs\": false\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e955e-0a18-4da0-a428-f4883fbb8d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI,AzureOpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "os.environ[\"OPENAI_API_TYPE\"] = 'azure'\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://exl-poc-demo.openai.azure.com/'\n",
    "os.environ[\"OPENAI_API_KEY\"] = '5588b6e4a35949458cd783e3fe61f960'\n",
    "\n",
    "llm = AzureChatOpenAI(**{'deployment_name':'exl_gpt_4o','openai_api_version':'2024-02-15-preview'},temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257e19f5-d619-4ec2-a70a-89d6d0ea0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt =  \"Provide a concise answer for the {question} from the retrived documents: {docs}\"\n",
    "prompt_template = PromptTemplate(template=prompt,input_variables=[\"question\",\"docs\"])\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"what is the difference between simple and traditional ira \"\n",
    "\n",
    "docs = vector_store_from_client.similarity_search(question, k=4)\n",
    "res=chain.invoke({\"question\":question,\"docs\":format_docs(docs),\"chat_history\":chat_history})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1b85d-25d2-42b9-9f99-cdcd4ac48e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=chain.invoke({\"question\":question,\"docs\":format_docs(docs),\"chat_history\":chat_history})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16f525-ff07-48f3-8d86-a0ac708c5323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "\tprint(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca56eb-feb7-493d-a9c1-ff211290bafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "982ac7aa-af44-4bd7-b211-c2e73d02e0a7",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe55b02-ad35-42c1-b3ba-e87df41e584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = \"Yes, there are some restrictions. Funds must be used for qualified education expenses to remain tax-free. Qualified expenses include tuition, fees, books, supplies, and room and board for students enrolled at least half-time. If you use the funds for non-qualified expenses, the earnings will be subject to federal income tax and a 10% penalty.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08541e27-b4f3-4799-a747-86eb77530bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "   '''Can you just provide a similarity score between these 2 strings, nothing else:\n",
    "    string1: {gt}\n",
    "    string2: {rag_output}\n",
    "    output fromat: {{'score':numeric value for the similarity score}}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46e5f9-004b-4643-a52e-8b4f48f47af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = prompt2.invoke({'gt':gt, 'rag_output':rag_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ce269-d039-4cc1-9ce3-c29c949affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.messages[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038cfd8-5041-46ea-8241-8aa65e059c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb476d91-94e7-4900-b64c-70db3beadc33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = llm.invoke(pr.messages[0].content)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978b7b1-0128-4817-b821-21588088a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecc022-70d3-438b-8d88-d31cb0b382fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d26303-f273-4d2c-9e45-1facf7dbf4c1",
   "metadata": {},
   "source": [
    "## CCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c256e-4c7b-4a2b-9b24-8fe64fa4d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_title(document_text: str, document_title_guidance: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Extract the title of a document using a language model.\n",
    "\n",
    "    Args:\n",
    "        document_text (str): The text of the document.\n",
    "        document_title_guidance (str, optional): Additional guidance for title extraction. Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted document title.\n",
    "    \"\"\"\n",
    "\n",
    "\t# Constants\n",
    "    DOCUMENT_TITLE_PROMPT = \"\"\"\n",
    "\tINSTRUCTIONS\n",
    "\tWhat is the title of the following document?\n",
    "\t\n",
    "\tYour response MUST be the title of the document, and nothing else. DO NOT respond with anything else.\n",
    "\t\n",
    "\t{document_title_guidance}\n",
    "\t\n",
    "\t{truncation_message}\n",
    "\t\n",
    "\tDOCUMENT\n",
    "\t{document_text}\n",
    "\t\"\"\".strip()\n",
    "\t\n",
    "    TRUNCATION_MESSAGE = \"\"\"\n",
    "\tAlso note that the document text provided below is just the first ~{num_words} words of the document. That should be plenty for this task. Your response should still pertain to the entire document, not just the text provided below.\n",
    "\t\"\"\".strip()\n",
    "    prompt_template = PromptTemplate(template=DOCUMENT_TITLE_PROMPT,input_variables=[\"document_text\",\"truncation_message\",\"document_title_guidance\"])\n",
    "    chain = prompt_template | llm | StrOutputParser()\n",
    "    return chain.invoke({\"document_text\":document_text,\"truncation_message\":TRUNCATION_MESSAGE,\"document_title_guidance\":\"\"})\n",
    "    \n",
    "    # return make_llm_call(chat_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f849258-cf0e-4cb2-81d3-5760737ebbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = \"\\n\".join(docs[0].page_content.split('\\n\\n')[2:])\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb09d4-be88-4f92-aa27-f4a770e81862",
   "metadata": {},
   "outputs": [],
   "source": [
    "           ########################testing with sections ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697c6da-d08d-4ab4-9955-00938cdc5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = get_document_title(chunk)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81ab6f-9220-4361-80c3-9c5d70d89358",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_w_header = f\"Document Title: {title}\\n\\n{chunk}\"\n",
    "print(chunk_w_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d759a-5030-4746-aa61-8f33e71a490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk=sections[3][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3373d8-0387-4647-b9ed-297be06f6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3bd89-1256-42eb-b64a-3818d5312bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49daf1fa-7cee-45eb-884d-1d4fe49cf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=get_document_title(chunk)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7625cc4-6c1e-49c2-b833-9faaa32d1bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3bd4d-09d4-4872-a474-66e42d2be593",
   "metadata": {},
   "source": [
    "## Re-Ranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9983ff7-e01b-4a2e-99ad-92f907804f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "cross_encoder = CrossEncoder('demo_api/model/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62380a-6559-4e4f-a4d2-93e04a0b6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_into_chunks(text: str, chunk_size: int):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0, length_function=len)\n",
    "    texts = text_splitter.create_documents([text])\n",
    "    chunks = [text.page_content for text in texts]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "# cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
    "# k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
    "# rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
    "\n",
    "def get_relevant_documents(query,vectorstore,cross_encoder,k,rerank_top_k):\n",
    "\t# Initial retrieval\n",
    "\tchunks = []\n",
    "\tinitial_docs = vectorstore.similarity_search(query, k=k)\n",
    "\t# for doc in initial_docs:\n",
    "\t# \tchunks.extend(split_into_chunks(doc.page_content, 30))\n",
    "\t# Prepare pairs for cross-encoder\n",
    "\tpairs = [[query,doc.page_content] for doc in initial_docs]\n",
    "\t\n",
    "\t# Get cross-encoder scores\n",
    "\tscores = cross_encoder.predict(pairs)\n",
    "\t\n",
    "\t# Sort documents by score\n",
    "\tscored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\t\n",
    "\t# Return top reranked documents\n",
    "\treturn [doc for doc, _ in scored_docs[:rerank_top_k]],[score for _, score in scored_docs[:rerank_top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8036f-8b79-4b43-a5ba-7ae18f00fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is a monetary policy\"\n",
    "k = 7\n",
    "rerank_top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f571f3-8b4d-4ddb-a46f-3ab56c6c9448",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results,filtered_score = get_relevant_documents(query,vector_store,cross_encoder,k,rerank_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9882816-2421-4ba8-a81d-3c93f452d4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for result in filtered_results:\n",
    "    print(f\"Response: {result.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b4a12-2b51-41ad-90e9-d1e51c8493c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb4519-ac99-459a-b7f6-21a84b8f2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "x=beta.cdf(filtered_score[0], 0.4, 0.4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f98fae-9e76-4084-be15-67a8e354c9a3",
   "metadata": {},
   "source": [
    "## RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8440d84-c5e0-4bec-8a69-e30ff2d8452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_segments(relevance_values: list, max_length: int, overall_max_length: int, minimum_value: float):\n",
    "    \"\"\"\n",
    "    This function takes the chunk relevance values and then runs an optimization algorithm to find the best segments. In more technical terms, it solves a constrained version of the maximum sum subarray problem.\n",
    "\n",
    "    Note: this is a simplified implementation intended for demonstration purposes. A more sophisticated implementation would be needed for production use and is available in the dsRAG library.\n",
    "\n",
    "    Args:\n",
    "        relevance_values (list): a list of relevance values for each chunk of a document\n",
    "        max_length (int): the maximum length of a single segment (measured in number of chunks)\n",
    "        overall_max_length (int): the maximum length of all segments (measured in number of chunks)\n",
    "        minimum_value (float): the minimum value that a segment must have to be considered\n",
    "\n",
    "    Returns:\n",
    "        best_segments (list): a list of tuples (start, end) that represent the indices of the best segments (the end index is non-inclusive) in the document\n",
    "        scores (list): a list of the scores for each of the best segments\n",
    "    \"\"\"\n",
    "    best_segments = []\n",
    "    scores = []\n",
    "    total_length = 0\n",
    "    while total_length < overall_max_length:\n",
    "        # find the best remaining segment\n",
    "        best_segment = None\n",
    "        best_value = -1000\n",
    "        for start in range(len(relevance_values)):\n",
    "            # skip over negative value starting points\n",
    "            if relevance_values[start] < 0:\n",
    "                continue\n",
    "            for end in range(start+1, min(start+max_length+1, len(relevance_values)+1)):\n",
    "                # skip over negative value ending points\n",
    "                if relevance_values[end-1] < 0:\n",
    "                    continue\n",
    "                # check if this segment overlaps with any of the best segments and skip if it does\n",
    "                if any(start < seg_end and end > seg_start for seg_start, seg_end in best_segments):\n",
    "                    continue\n",
    "                # check if this segment would push us over the overall max length and skip if it would\n",
    "                if total_length + end - start > overall_max_length:\n",
    "                    continue\n",
    "                \n",
    "                # define segment value as the sum of the relevance values of its chunks\n",
    "                segment_value = sum(relevance_values[start:end])\n",
    "                if segment_value > best_value:\n",
    "                    best_value = segment_value\n",
    "                    best_segment = (start, end)\n",
    "        \n",
    "        # if we didn't find a valid segment then we're done\n",
    "        if best_segment is None or best_value < minimum_value:\n",
    "            break\n",
    "\n",
    "        # otherwise, add the segment to the list of best segments\n",
    "        best_segments.append(best_segment)\n",
    "        scores.append(best_value)\n",
    "        total_length += best_segment[1] - best_segment[0]\n",
    "    \n",
    "    return best_segments, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f52e5-2a77-47aa-8f21-f6bf701683b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters and constraints for the optimization\n",
    "irrelevant_chunk_penalty = 0.2 # empirically, something around 0.2 works well; lower values bias towards longer segments\n",
    "max_length = 20\n",
    "overall_max_length = 30\n",
    "minimum_value = 0.7\n",
    "\n",
    "# subtract constant threshold value from chunk relevance values\n",
    "relevance_values = [v - irrelevant_chunk_penalty for v in chunk_values] \n",
    "\n",
    "# run the optimization\n",
    "best_segments, scores = get_best_segments(relevance_values, max_length, overall_max_length, minimum_value)\n",
    "\n",
    "# print results\n",
    "print (\"Best segment indices\")\n",
    "print (best_segments) # indices of the best segments, with the end index non-inclusive\n",
    "print ()\n",
    "print (\"Best segment scores\")\n",
    "print (scores)\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff995b29-77bb-423c-bd83-36ce1345b06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce1af8-ae8a-483a-9c69-d497fec9303b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95d630b9-583a-4f02-a66d-cc64d8c8b4a1",
   "metadata": {},
   "source": [
    "## Question Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7282825-137e-4895-adb6-3490f2b505a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI,AzureOpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "os.environ[\"OPENAI_API_TYPE\"] = 'azure'\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://exl-poc-demo.openai.azure.com/'\n",
    "os.environ[\"OPENAI_API_KEY\"] = '5588b6e4a35949458cd783e3fe61f960'\n",
    "\n",
    "llm = AzureChatOpenAI(**{'deployment_name':'exl_gpt_4o','openai_api_version':'2024-02-15-preview'},temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4afa47-f1c8-4cb3-ba44-cac9ee00c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = \"\"\"Construct 20 questions from the below provided documents: {docs}\n",
    "\n",
    "DO NOT construct simple question that is already present in documents or is the title to a topic.\n",
    "output should be a list of dictionary having keys question and answer.\n",
    "Output Schema:\n",
    "[{{'question':str,'answer':str}},....]\n",
    "where question is the question and answer is its correct response.\"\"\"\n",
    "prompt_template = PromptTemplate(template=prompt,input_variables=[\"docs\"])\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
    "\n",
    "# question = \"what is the difference between simple and traditional ira \"\n",
    "\n",
    "# docs = vector_store_from_client.similarity_search(question, k=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0c0b5-a6d8-4a17-bdc6-56f0f24455ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390281b8-75eb-402c-8a66-807e58515b58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res=chain.invoke({\"docs\":format_docs(documents)})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea85d34-ce7d-476d-96fc-28520f439b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_prompt_template= PromptTemplate(\n",
    "    input_variables=[\"user_input\",\"conversation_history\"],\n",
    "    template=\"\"\"\n",
    "\tYou are an AI assistant that checks if a question has already been asked in the conversation history. If the current question is semantically similar to any previous question or any previous answer, return `yes`. If not, return `no`. **If the answer is `yes`, give the response using the conversation history and rephrase the answer according to the question asked by the user, don't give the response as it is**.\n",
    "    question:\n",
    "    {user_input}\n",
    "\n",
    "    conversation history:\n",
    "    {conversation_history}\n",
    "\t\n",
    "\"\"\")\n",
    "llm_chain=similarity_prompt_template|llm|StrOutputParser()\n",
    "\n",
    "chat_history = ['What is an IRA?', 'An IRA (Individual Retirement Account) is a tax-advantaged savings account designed to help you save for retirement. There are several types of IRAs, each with its own features and benefits.', 'What are the types of it?', \"Commercial Banks:\\n\\nFocused on accepting deposits, making loans, and providing basic financial services to the public.\\n\\nInvestment Banks:\\n\\nSpecialize in helping businesses and governments raise capital, managing investments, and providing advisory services for mergers and acquisitions.\\n\\nCentral Banks:\\n\\nResponsible for managing a country's currency, money supply, and interest rates (e.g., Federal Reserve in the USA).\\n\\nRetail Banks:\\n\\nProvide consumer-oriented services like savings accounts, mortgages, and personal loans.\\n\\nCredit Unions:\\n\\nMember-owned financial cooperatives that provide similar services as retail banks but often at more favorable rates.\"]\n",
    "query = \"Do IRA have any kind of retirement benefit?\"\n",
    "\n",
    "is_similar=llm_chain.invoke({\"conversation_history\":chat_history,\"user_input\":query})\n",
    "print(is_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef063d1d-8aa2-4811-9d60-c21a7d07b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(user_input, conversation_history):\n",
    "    similarity_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"conversation_history\"],\n",
    "        template=\"\"\"\n",
    "        You are an AI assistant that checks if a question has already been asked in the conversation history. If the current question is semantically similar to any previous question or any previous answer, return `yes`. If not, return `no`. **If the answer is `yes`, give the response using the conversation history and rephrase the answer according to the question asked by the user, don't give the response as it is**.\n",
    "        question:\n",
    "        {user_input}\n",
    "\n",
    "        conversation history:\n",
    "        {conversation_history}\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm_chain=similarity_prompt_template|llm|StrOutputParser()\n",
    "    is_similar = llm_chain.invoke({\"conversation_history\": conversation_history, \"user_input\": user_input})\n",
    "    return is_similar\n",
    "\n",
    "# Example usage\n",
    "chat_history = [\n",
    "    'What is an IRA?', \n",
    "    'An IRA (Individual Retirement Account) is a tax-advantaged savings account designed to help you save for retirement. There are several types of IRAs, each with its own features and benefits.', \n",
    "    'What are the types of it?', \n",
    "    \"Commercial Banks:\\n\\nFocused on accepting deposits, making loans, and providing basic financial services to the public.\\n\\nInvestment Banks:\\n\\nSpecialize in helping businesses and governments raise capital, managing investments, and providing advisory services for mergers and acquisitions.\\n\\nCentral Banks:\\n\\nResponsible for managing a country's currency, money supply, and interest rates (e.g., Federal Reserve in the USA).\\n\\nRetail Banks:\\n\\nProvide consumer-oriented services like savings accounts, mortgages, and personal loans.\\n\\nCredit Unions:\\n\\nMember-owned financial cooperatives that provide similar services as retail banks but often at more favorable rates.\"\n",
    "]\n",
    "query = \"Do IRA have any kind of retirement benefit?\"\n",
    "\n",
    "is_similar = check_similarity(query, chat_history)\n",
    "print(is_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb50700-f726-4891-8aec-3e124a65cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_question_prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\",\"conversation_history\"],\n",
    "    template=\"\"\"You are an AI assistant that rephrases the current question based on the conversation history. If the current question references context from the conversation history, rephrase it to be a standalone question that includes the necessary context. Return the rephrased question.\n",
    "   \n",
    "\tquestion:\n",
    "    {user_input}\n",
    "\n",
    "    conversation history:\n",
    "    {conversation_history})\n",
    "\"\"\"\n",
    ")\n",
    "llm_chain=rephrase_question_prompt|llm|StrOutputParser()\n",
    "\n",
    "chat_history = [\n",
    "    'What is a bank?', \n",
    "    \"Commercial Banks:\\n\\nFocused on accepting deposits, making loans, and providing basic financial services to the public.\\n\\nInvestment Banks:\\n\\nSpecialize in helping businesses and governments raise capital, managing investments, and providing advisory services for mergers and acquisitions.\\n\\nCentral Banks:\\n\\nResponsible for managing a country's currency, money supply, and interest rates (e.g., Federal Reserve in the USA).\\n\\nRetail Banks:\\n\\nProvide consumer-oriented services like savings accounts, mortgages, and personal loans.\\n\\nCredit Unions:\\n\\nMember-owned financial cooperatives that provide similar services as retail banks but often at more favorable rates.\",\n",
    "'What are its types?', \n",
    "]\n",
    "query = \"What are its benefits?\"\n",
    "rephrased_query = llm_chain.invoke({\"conversation_history\":chat_history,\"user_input\":query})\n",
    "print(rephrased_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b78b11-6d9f-422a-9a61-c3c8e83d00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_question(user_input, conversation_history):\n",
    "    rephrase_question_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"conversation_history\"],\n",
    "        template=\"\"\"You are an AI assistant that rephrases the current question based on the conversation history. If the current question references context from the conversation history, rephrase it to be a standalone question that includes the necessary context. Return the rephrased question.\n",
    "        \n",
    "        question:\n",
    "        {user_input}\n",
    "\n",
    "        conversation history:\n",
    "        {conversation_history})\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm_chain = rephrase_question_prompt|llm|StrOutputParser()\n",
    "    rephrased_query = llm_chain.invoke({\"conversation_history\": conversation_history, \"user_input\": user_input})\n",
    "    return rephrased_query\n",
    "\n",
    "# Example usage\n",
    "chat_history = [\n",
    "    'What is a bank?', \n",
    "    \"Commercial Banks:\\n\\nFocused on accepting deposits, making loans, and providing basic financial services to the public.\\n\\nInvestment Banks:\\n\\nSpecialize in helping businesses and governments raise capital, managing investments, and providing advisory services for mergers and acquisitions.\\n\\nCentral Banks:\\n\\nResponsible for managing a country's currency, money supply, and interest rates (e.g., Federal Reserve in the USA).\\n\\nRetail Banks:\\n\\nProvide consumer-oriented services like savings accounts, mortgages, and personal loans.\\n\\nCredit Unions:\\n\\nMember-owned financial cooperatives that provide similar services as retail banks but often at more favorable rates.\",\n",
    "    'What are its types?',\n",
    "\t'What is a simple IRA'\n",
    "]\n",
    "query = \"What are its benefits\"\n",
    "rephrased_query = rephrase_question(query, chat_history)\n",
    "print(rephrased_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3be1d-b9c3-43c7-9d86-9d70cb4ad4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0d6c5-4c96-42f9-a4fc-20619c8b0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8cb89-488f-47ff-8f2a-d065ed9bcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f759b-7122-4586-b7a0-2966aa0c364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c5b37-0b06-4279-ae8e-3a80409d145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rephrased_query(query, chat_history):\n",
    "    # Combine the input into a single dictionary\n",
    "    input_data = {\n",
    "        \"question\": query,\n",
    "        \"chat_history\": chat_history\n",
    "    }\n",
    "    # Invoke the retriever with the combined input\n",
    "    rephrased_query = history_aware_retriever.invoke(input_data)\n",
    "    return rephrased_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b6d9b-a877-429d-abef-c72c87c76c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain  # Import the create_retrieval_chain function from the langchain.chains module\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3132e-9851-47ea-b4b7-48725ea3b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "qa_system_prompt =  \"Provide a concise answer for the {question} from the retrived documents: {context}\"\n",
    "qa_prompt_template = PromptTemplate(template=qa_system_prompt,input_variables=[\"question\",\"context\"])\n",
    "chain = qa_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# Convert loaded documents into strings by concatenating their content\n",
    "# and ignoring metadata\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"what is the difference between simple and traditional ira \"\n",
    "\n",
    "docs = vector_store_from_client.similarity_search(question, k=4)\n",
    "res=chain.invoke({\"question\":question,\"context\":format_docs(docs),\"chat_history\":chat_history})\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e366ed-3182-4e51-9a78-0ae67ec574ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23ec4c-1b69-4f35-b744-28e177359dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0b00c-2965-4cf7-88ba-a2297f60ba56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage  # Import the HumanMessage class\n",
    "\n",
    "chat_history = []  # Initialize an empty list to store the chat history\n",
    "\n",
    "# Ask the first question\n",
    "first_question = \"What is LLM?\"\n",
    "ai_response_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})  # Invoke the RAG chain with the question and an empty chat history\n",
    "print('user query:', first_question) \n",
    "print('ai response:', ai_response_1[\"answer\"])  # Print the answer from the RAG chain\n",
    "chat_history.extend([HumanMessage(content=first_question), ai_response_1[\"answer\"]])  # Add the question and answer to the chat history\n",
    "\n",
    "# Ask the second question\n",
    "second_question = \"What are the different types of it?\"\n",
    "ai_response_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})  # Invoke the RAG chain with the second question and the updated chat history\n",
    "chat_history.extend([HumanMessage(content=second_question), ai_response_2[\"answer\"]])  # Add the second question and answer to the chat history\n",
    "print('user query:', (second_question)) \n",
    "print('ai response:', ai_response_2[\"answer\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7809afd-a844-47e8-93c0-0b795c6b3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_question(user_input, conversation_history):\n",
    "    rephrase_question_prompt = PromptTemplate(\n",
    "        input_variables=[\"user_input\", \"conversation_history\"],\n",
    "        template=\"\"\"You are an AI assistant that rephrases the current question based on the conversation history. If the current question references context from the conversation history, rephrase it to be a standalone question that includes the necessary context. Return the rephrased question.\n",
    "        \n",
    "        question:\n",
    "        {user_input}\n",
    "\n",
    "        conversation history:\n",
    "        {conversation_history})\n",
    "        \"\"\"\n",
    "    )\n",
    "    llm_chain = LLMChain(prompt=rephrase_question_prompt, llm=llm, output_parser=StrOutputParser())\n",
    "    rephrased_query = llm_chain.invoke({\"conversation_history\": conversation_history, \"user_input\": user_input})\n",
    "    return rephrased_query\n",
    "\n",
    "# Example usage\n",
    "chat_history = [\n",
    "    'What is a bank?', \n",
    "    \"Commercial Banks:\\n\\nFocused on accepting deposits, making loans, and providing basic financial services to the public.\\n\\nInvestment Banks:\\n\\nSpecialize in helping businesses and governments raise capital, managing investments, and providing advisory services for mergers and acquisitions.\\n\\nCentral Banks:\\n\\nResponsible for managing a country's currency, money supply, and interest rates (e.g., Federal Reserve in the USA).\\n\\nRetail Banks:\\n\\nProvide consumer-oriented services like savings accounts, mortgages, and personal loans.\\n\\nCredit Unions:\\n\\nMember-owned financial cooperatives that provide similar services as retail banks but often at more favorable rates.\",\n",
    "    'What are its types?', \n",
    "]\n",
    "query = \"What are its benefits?\"\n",
    "rephrased_query = rephrase_question(query, chat_history)\n",
    "print(rephrased_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed05134-4455-4d1a-8c28-8f93b45b3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf562d-bcc2-44b0-969a-476abb4a9413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class isimilar_output(BaseModel):\n",
    "    flag: str = Field(description=\"return string value True/False. if satisfy then True else False\")\n",
    "    response: str = Field(description=\"answer to the particular question present in conversation history if is_similar is True or return empty\")\n",
    "parser = JsonOutputParser(pydantic_object=isimilar_output)\n",
    "similarity_prompt_template = PromptTemplate(\n",
    " input_variables=[\"user_input\", \"conversation_history\"],\n",
    " partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    " template=\"\"\"You are an AI assistant that checks if answer to a question can be fetched from the provided conversation history. If the current question is semantically similar to any previous question or any previous answer, return \"True\", else return \"False\".\n",
    " If it returns \"True\", fetch the answer to that particular question **only using the conversation history** and rephrase it according to the question asked and give the response using conversational fillers to make it sound more natural.\n",
    "    return output as a json having keys flag and response only. If it returns \"False\", return empty in response. \n",
    "\n",
    "    outpiy schema:\n",
    "    {{flag: str,\n",
    "    response: str}}\n",
    "    \n",
    " question:\n",
    " {user_input}\n",
    " \n",
    " conversation history:\n",
    " {conversation_history}\n",
    " \"\"\"\n",
    ")\n",
    "chain=similarity_prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb51e22-8d3a-4eb3-ab35-0760798f6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = ['hi', 'Hey there! Looks like you’ve got a question—what’s on your mind?',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01c2b4-40ff-47f1-b187-395bcb47a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'hi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659a19f-169e-448e-abbb-859dcfbcd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = chain.invoke({\"conversation_history\": conversation_history, \"user_input\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c42ae9-aafd-4265-9c82-0b721d807ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caee0f-2d45-4a48-925a-29f1ed981988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289795a4-d929-46af-982d-09e6e856a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are an AI assistant that checks if answer to a question can be fetched from the provided conversation history. If the current question is semantically similar to any previous question or any previous answer, return \"True\", else return \"False\".\n",
    " If it returns \"True\", fetch the answer to that particular question **only using the conversation history** and rephrase it according to the question asked and give the response using conversational fillers to make it sound more natural.    \n",
    "         Return output as a json having keys flag and response only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
